{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/hanolda/salt-identification-challange---Kaggle/blob/master/Example.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "-_4W1QKrhIJe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "746b5667-56e4-45e2-8c90-8e29d572f16e"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2\n",
        "\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Lambda\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "_OLTCI83hS4t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set some parameters\n",
        "im_width = 128\n",
        "im_height = 128\n",
        "im_chan = 1\n",
        "path_train = '../input/train/'\n",
        "path_test = '../input/test/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dFnwekH_gr57",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Exploration\n",
        "\n",
        "Let's look at some data. We can see that TGS chose to use very varied data by inspecting. That is great and adresses a problem in deep learning geoscience at the moment. We build models on one type of seismic and have no idea whether it generalizes.\n"
      ]
    },
    {
      "metadata": {
        "id": "k0Ne-GakgarG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "0T2IOPCOg1Ws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "a57e48f3-71ac-4935-e2db-8bde16f8f2f2"
      },
      "cell_type": "code",
      "source": [
        "ids= ['1f1cc6b3a4','5b7c160d0d','6c40978ddf','7dfdf6eeb8','7e5a6e5013']\n",
        "plt.figure(figsize=(20,10))\n",
        "for j, img_name in enumerate(ids):\n",
        "    q = j+1\n",
        "    img = load_img('../input/train/images/' + img_name + '.png')\n",
        "    img_mask = load_img('../input/train/masks/' + img_name + '.png')\n",
        "    \n",
        "    plt.subplot(1,2*(1+len(ids)),q*2-1)\n",
        "    plt.imshow(img)\n",
        "    plt.subplot(1,2*(1+len(ids)),q*2)\n",
        "    plt.imshow(img_mask)\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-1b9098504d34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/train/images/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mimg_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/train/masks/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, target_size, interpolation)\u001b[0m\n\u001b[1;32m    385\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    386\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[0;32m--> 387\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2312\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2314\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/train/images/1f1cc6b3a4.png'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2c4690bda0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "TFnbH9lQizwt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have many examples without salt, as you can see by the masks that are entirely dark. That's great, an algorithm we build will then know that patches exist entirely without salt. Talk about biasing your data.\n",
        "\n",
        "We can draw heavily on other work, instead of regurgitating the geophysics work that has been done before. I mentioned that seismic is kind of like ultrasound. So I had a look at https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277\n",
        "\n",
        "Let's throw a Unet at our data. I am blatanly stealing from Ketil at this point. All credit goes to him and his nice code. First we'll need to get our data into a shape that works for U-Nets. That means, it should be a power of 2. Let's do it quick and dirty for now, but eventually, consider aliasing and all that fun."
      ]
    },
    {
      "metadata": {
        "id": "fjxyoZNKi1GG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "3bedc06a-89c5-4f47-ecdf-0d0dcaf0c670"
      },
      "cell_type": "code",
      "source": [
        "train_ids = next(os.walk(path_train+\"images\"))[2]\n",
        "test_ids = next(os.walk(path_test+\"images\"))[2]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "StopIteration",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-859824ffa5c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_train\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_test\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "JVwcWihti5i0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get and resize train images and masks\n",
        "X_train = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
        "Y_train = np.zeros((len(train_ids), im_height, im_width, 1), dtype=np.bool)\n",
        "print('Getting and resizing train images and masks ... ')\n",
        "sys.stdout.flush()\n",
        "for n, id_ in tqdm_notebook(enumerate(train_ids), total=len(train_ids)):\n",
        "    path = path_train\n",
        "    img = load_img(path + '/images/' + id_)\n",
        "    x = img_to_array(img)[:,:,1]\n",
        "    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n",
        "    X_train[n] = x\n",
        "    mask = img_to_array(load_img(path + '/masks/' + id_))[:,:,1]\n",
        "    Y_train[n] = resize(mask, (128, 128, 1), mode='constant', preserve_range=True)\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jQS3hPsAi-uz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Check if training data looks all right\n",
        "ix = random.randint(0, len(train_ids))\n",
        "plt.imshow(np.dstack((X_train[ix],X_train[ix],X_train[ix])))\n",
        "plt.show()\n",
        "tmp = np.squeeze(Y_train[ix]).astype(np.float32)\n",
        "plt.imshow(np.dstack((tmp,tmp,tmp)))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UN9b1P6SjFgp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train Model\n",
        "Our task, just like the segmentation task for nuclei, is evaluated on the mean IoU metric. This one isn't in keras, but obviously, we're stealing this one too from Ketil.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "gX3V3v0ujCY9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define IoU metric\n",
        "def mean_iou(y_true, y_pred):\n",
        "    prec = []\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        y_pred_ = tf.to_int32(y_pred > t)\n",
        "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
        "        K.get_session().run(tf.local_variables_initializer())\n",
        "        with tf.control_dependencies([up_opt]):\n",
        "            score = tf.identity(score)\n",
        "        prec.append(score)\n",
        "    return K.mean(K.stack(prec), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FHjJ5knhjPMC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is the fun part. Building the sequential Model. The U-Net is basically looking like an Auto-Encoder with shortcuts.\n",
        "\n",
        "We're also sprinkling in some earlystopping to prevent overfitting. If you're running this on kaggle, this is the point, you want to have GPU support."
      ]
    },
    {
      "metadata": {
        "id": "71lEGnq4jXAU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build U-Net model\n",
        "inputs = Input((im_height, im_width, im_chan))\n",
        "s = Lambda(lambda x: x / 255) (inputs)\n",
        "\n",
        "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)\n",
        "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n",
        "p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n",
        "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n",
        "p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n",
        "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n",
        "p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n",
        "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n",
        "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\n",
        "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n",
        "\n",
        "u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "u6 = concatenate([u6, c4])\n",
        "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n",
        "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n",
        "\n",
        "u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "u7 = concatenate([u7, c3])\n",
        "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n",
        "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n",
        "\n",
        "u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "u8 = concatenate([u8, c2])\n",
        "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n",
        "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n",
        "\n",
        "u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "u9 = concatenate([u9, c1], axis=3)\n",
        "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n",
        "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n",
        "\n",
        "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "model = Model(inputs=[inputs], outputs=[outputs])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U7n9erIwjc1W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
        "checkpointer = ModelCheckpoint('model-tgs-salt-1.h5', verbose=1, save_best_only=True)\n",
        "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=8, epochs=30, \n",
        "                    callbacks=[earlystopper, checkpointer])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PIAQbfXTjgdy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Test Data\n",
        "First we'll get the test data. This takes a while, it's 18000 samples."
      ]
    },
    {
      "metadata": {
        "id": "7tvx79ipjhyT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get and resize test images\n",
        "X_test = np.zeros((len(test_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
        "sizes_test = []\n",
        "print('Getting and resizing test images ... ')\n",
        "sys.stdout.flush()\n",
        "for n, id_ in tqdm_notebook(enumerate(test_ids), total=len(test_ids)):\n",
        "    path = path_test\n",
        "    img = load_img(path + '/images/' + id_)\n",
        "    x = img_to_array(img)[:,:,1]\n",
        "    sizes_test.append([x.shape[0], x.shape[1]])\n",
        "    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n",
        "    X_test[n] = x\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gG3tihF8jnMy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Predict on train, val and test\n",
        "model = load_model('model-tgs-salt-1.h5', custom_objects={'mean_iou': mean_iou})\n",
        "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
        "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
        "preds_test = model.predict(X_test, verbose=1)\n",
        "\n",
        "# Threshold predictions\n",
        "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
        "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
        "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mYxb9r7Gjprf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create list of upsampled test masks\n",
        "preds_test_upsampled = []\n",
        "for i in tnrange(len(preds_test)):\n",
        "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
        "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
        "                                       mode='constant', preserve_range=True))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7tmiOi0PjslT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "preds_test_upsampled[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FaVf3_Oqjuoa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We'll look at it again, just to be sure."
      ]
    },
    {
      "metadata": {
        "id": "ruPxbmu0jwuo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Perform a sanity check on some random training samples\n",
        "ix = random.randint(0, len(preds_train_t))\n",
        "plt.imshow(np.dstack((X_train[ix],X_train[ix],X_train[ix])))\n",
        "plt.show()\n",
        "tmp = np.squeeze(Y_train[ix]).astype(np.float32)\n",
        "plt.imshow(np.dstack((tmp,tmp,tmp)))\n",
        "plt.show()\n",
        "tmp = np.squeeze(preds_train_t[ix]).astype(np.float32)\n",
        "plt.imshow(np.dstack((tmp,tmp,tmp)))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fjxVKvQPj0bR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prepare Submission\n",
        "We need to prepare the submission. A nice CSV with predictions. All of this is one to one from Ketil and does not differ from any of the other segmentation tasks. Check them out to improve on this.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nSahjqDmj9qm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def RLenc(img, order='F', format=True):\n",
        "    \"\"\"\n",
        "    img is binary mask image, shape (r,c)\n",
        "    order is down-then-right, i.e. Fortran\n",
        "    format determines if the order needs to be preformatted (according to submission rules) or not\n",
        "\n",
        "    returns run length as an array or string (if format is True)\n",
        "    \"\"\"\n",
        "    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n",
        "    runs = []  ## list of run lengths\n",
        "    r = 0  ## the current run length\n",
        "    pos = 1  ## count starts from 1 per WK\n",
        "    for c in bytes:\n",
        "        if (c == 0):\n",
        "            if r != 0:\n",
        "                runs.append((pos, r))\n",
        "                pos += r\n",
        "                r = 0\n",
        "            pos += 1\n",
        "        else:\n",
        "            r += 1\n",
        "\n",
        "    # if last run is unsaved (i.e. data ends with 1)\n",
        "    if r != 0:\n",
        "        runs.append((pos, r))\n",
        "        pos += r\n",
        "        r = 0\n",
        "\n",
        "    if format:\n",
        "        z = ''\n",
        "\n",
        "        for rr in runs:\n",
        "            z += '{} {} '.format(rr[0], rr[1])\n",
        "        return z[:-1]\n",
        "    else:\n",
        "        return runs\n",
        "\n",
        "pred_dict = {fn[:-4]:RLenc(np.round(preds_test_upsampled[i])) for i,fn in tqdm_notebook(enumerate(test_ids))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ELPhvRUkApq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
        "sub.index.names = ['id']\n",
        "sub.columns = ['rle_mask']\n",
        "sub.to_csv('submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}